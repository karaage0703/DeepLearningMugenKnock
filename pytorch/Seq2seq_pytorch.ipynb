{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Seq2seq_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoyoyo-yo/DeepLearningMugenKnock/blob/master/Scripts_NLP/pytorch/Seq2seq_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0H8bE7gkhEV",
        "colab_type": "text"
      },
      "source": [
        "# Seq2seq English - Franch\n",
        "\n",
        "元論文 : Sequence to Sequence Learning with Neural Networks https://arxiv.org/abs/1409.3215?context=cs (2014)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIRpEHgCkoE0",
        "colab_type": "code",
        "outputId": "12333edd-0112-47e2-f652-ff17dbbd7729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install numpy matplotlib opencv-python torch torchvision torchsummary pandas easydict"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6j-kiToPUyo",
        "colab_type": "text"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjoKf_PPQdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b9902edb-f075-4519-9ee2-e4ba37d032f6"
      },
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-09 06:24:35--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:3037::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5982778 (5.7M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip.1’\n",
            "\n",
            "\rfra-eng.zip.1         0%[                    ]       0  --.-KB/s               \rfra-eng.zip.1        14%[=>                  ] 859.10K  4.11MB/s               \rfra-eng.zip.1       100%[===================>]   5.71M  18.3MB/s    in 0.3s    \n",
            "\n",
            "2020-05-09 06:24:36 (18.3 MB/s) - ‘fra-eng.zip.1’ saved [5982778/5982778]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZlRB8duPQjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "def load_ds():\n",
        "    #\n",
        "    _chars = '!?/.'\n",
        "    corpus1 = []\n",
        "    corpus2 = []\n",
        "\n",
        "    data1 = []\n",
        "    data2 = []\n",
        "\n",
        "    with zipfile.ZipFile('fra-eng.zip') as z:\n",
        "        with z.open('fra.txt') as f:\n",
        "            lines = f.readlines()\n",
        "            for x in lines[:100]:\n",
        "                lang1, lang2, _ = [y.rstrip() for y in x.decode('utf-8').split('\\t')]\n",
        "                corpus1 += [w.rstrip(_chars) for w in lang1.split(' ')] #list(set(corpus1) | set(list(lang1.split(' '))))\n",
        "                corpus2 += [w.rstrip(_chars).rstrip('\\u202f') for w in lang2.split(' ')] #list(set(corpus2) | set(list(lang2.split(' '))))\n",
        "                #print([y.rstrip() for y in x.decode('utf-8').split('\\t')])\n",
        "\n",
        "            corpus1 = list(set(corpus1)) # drop duplicate\n",
        "            corpus1.sort()\n",
        "            corpus1 = ['<SOS>', '<EOS>', '<UNKNOWN>'] + list(_chars) + corpus1\n",
        "            corpus2 = list(set(corpus2)) # drop duplicate\n",
        "            corpus2.sort()\n",
        "            corpus2 = ['<SOS>', '<EOS>', '<UNKNOWN>'] + list(_chars) + corpus2\n",
        "\n",
        "            for x in lines[:100]:\n",
        "                lang1, lang2, _ = [y.rstrip() for y in x.decode('utf-8').split('\\t')]\n",
        "                data1 += [[corpus1.index('<SOS>')] + [corpus1.index(w.rstrip(_chars)) for w in lang1.split(' ')] + [corpus1.index('<EOS>')]]\n",
        "                data2 += [[corpus2.index('<SOS>')] + [corpus2.index(w.rstrip(_chars).rstrip('\\u202f')) for w in lang2.split(' ')] + [corpus2.index('<EOS>')]]\n",
        "\n",
        "    return {'corpus1' : corpus1, 'corpus2' : corpus2, 'data1' : data1, 'data2' : data2} \n",
        "\n",
        "data_dict = load_ds()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ64UhTzkhEW",
        "colab_type": "text"
      },
      "source": [
        "## Import and Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JWBAlBskhEX",
        "colab_type": "code",
        "outputId": "f2848404-d6a5-4fc3-d6af-0191dfa4c46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from easydict import EasyDict\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "#---\n",
        "# config\n",
        "#---\n",
        "cfg = EasyDict()\n",
        "\n",
        "cfg.CORPUS1_NUM = len(data_dict['corpus1'])\n",
        "cfg.CORPUS2_NUM =  len(data_dict['corpus2'])\n",
        "\n",
        "# Seq2seq config\n",
        "cfg.SEQ2SEQ_MAX_LENGTH = 1000 # decoder max output length\n",
        "cfg.SEQ2SEQ_TRAIN_FORCE_PROB = 0.5 # train input is forced to gt with this probability\n",
        "cfg.SEQ2SEQ_NEXT_WORD_SELECTION = 'prob' # prob, argmax\n",
        "\n",
        "cfg.SEQ2SEQ_HIDDEN_DIM = 512\n",
        "\n",
        "cfg.CHANNEL_AXIS = 1 # 1 ... [mb, c, h, w], 3 ... [mb, h, w, c]\n",
        "\n",
        "cfg.GPU = True\n",
        "cfg.DEVICE_TYPE = 'cuda' if cfg.GPU and torch.cuda.is_available() else 'cpu'\n",
        "cfg.DEVICE = torch.device(cfg.DEVICE_TYPE)\n",
        "\n",
        "# train\n",
        "cfg.TRAIN = EasyDict()\n",
        "cfg.TRAIN.DISPAY_ITERATION_INTERVAL = 50\n",
        "\n",
        "cfg.PREFIX = 'Seq2seq'\n",
        "cfg.TRAIN.MODEL_D_SAVE_PATH = 'models/' + cfg.PREFIX + '_D_{}.pt'\n",
        "cfg.TRAIN.MODEL_SAVE_INTERVAL = 200\n",
        "cfg.TRAIN.ITERATION = 10_000\n",
        "cfg.TRAIN.MINIBATCH = 32\n",
        "cfg.TRAIN.OPTIMIZER_E = torch.optim.Adam\n",
        "cfg.TRAIN.LEARNING_PARAMS_E = {'lr' : 0.01, 'betas' : (0., 0.9)}\n",
        "cfg.TRAIN.OPTIMIZER_D = torch.optim.Adam\n",
        "cfg.TRAIN.LEARNING_PARAMS_D = {'lr' : 0.01, 'betas' : (0., 0.9)}\n",
        "cfg.TRAIN.LOSS_FUNCTION = torch.nn.NLLLoss()\n",
        "\n",
        "cfg.TRAIN.DATA_PATH = '/content/drive/My Drive/Colab Notebooks/Dataset/train/images/'\n",
        "cfg.TRAIN.DATA_HORIZONTAL_FLIP = True # data augmentation : holizontal flip\n",
        "cfg.TRAIN.DATA_VERTICAL_FLIP = True # data augmentation : vertical flip\n",
        "cfg.TRAIN.DATA_ROTATION = 1 # data augmentation : rotation False, or integer\n",
        "\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE = True\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_INTERVAL = 200\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_IMAGE_PATH = 'result/' + cfg.PREFIX + '_result_{}.jpg'\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH = 'result/' + cfg.PREFIX + '_loss.txt'\n",
        "\n",
        "\n",
        "# test\n",
        "cfg.TEST = EasyDict()\n",
        "cfg.TEST.MODEL_D_PATH = cfg.TRAIN.MODEL_D_SAVE_PATH.format('final')\n",
        "cfg.TEST.DATA_PATH = '/content/drive/My Drive/Colab Notebooks/Dataset/test/images/'\n",
        "cfg.TEST.MINIBATCH = 10\n",
        "cfg.TEST.ITERATION = 2\n",
        "cfg.TEST.RESULT_SAVE = False\n",
        "cfg.TEST.RESULT_IMAGE_PATH = 'result/' + cfg.PREFIX + '_result_{}.jpg'\n",
        "\n",
        "# random seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "# make model save directory\n",
        "def make_dir(path):\n",
        "    if '/' in path:\n",
        "        model_save_dir = '/'.join(path.split('/')[:-1])\n",
        "        os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "make_dir(cfg.TRAIN.MODEL_D_SAVE_PATH)\n",
        "make_dir(cfg.TRAIN.LEARNING_PROCESS_RESULT_IMAGE_PATH)\n",
        "make_dir(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH)\n",
        "\n",
        "pprint(cfg)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'CHANNEL_AXIS': 1,\n",
            " 'CORPUS1_NUM': 64,\n",
            " 'CORPUS2_NUM': 132,\n",
            " 'DEVICE': device(type='cpu'),\n",
            " 'DEVICE_TYPE': 'cpu',\n",
            " 'GPU': True,\n",
            " 'PREFIX': 'Seq2seq',\n",
            " 'SEQ2SEQ_HIDDEN_DIM': 512,\n",
            " 'SEQ2SEQ_MAX_LENGTH': 1000,\n",
            " 'SEQ2SEQ_NEXT_WORD_SELECTION': 'prob',\n",
            " 'SEQ2SEQ_TRAIN_FORCE_PROB': 0.5,\n",
            " 'TEST': {'DATA_PATH': '/content/drive/My Drive/Colab '\n",
            "                       'Notebooks/Dataset/test/images/',\n",
            "          'ITERATION': 2,\n",
            "          'MINIBATCH': 10,\n",
            "          'MODEL_D_PATH': 'models/Seq2seq_D_final.pt',\n",
            "          'RESULT_IMAGE_PATH': 'result/Seq2seq_result_{}.jpg',\n",
            "          'RESULT_SAVE': False},\n",
            " 'TRAIN': {'DATA_HORIZONTAL_FLIP': True,\n",
            "           'DATA_PATH': '/content/drive/My Drive/Colab '\n",
            "                        'Notebooks/Dataset/train/images/',\n",
            "           'DATA_ROTATION': 1,\n",
            "           'DATA_VERTICAL_FLIP': True,\n",
            "           'DISPAY_ITERATION_INTERVAL': 50,\n",
            "           'ITERATION': 10000,\n",
            "           'LEARNING_PARAMS_D': {'betas': [0.0, 0.9], 'lr': 0.01},\n",
            "           'LEARNING_PARAMS_E': {'betas': [0.0, 0.9], 'lr': 0.01},\n",
            "           'LEARNING_PROCESS_RESULT_IMAGE_PATH': 'result/Seq2seq_result_{}.jpg',\n",
            "           'LEARNING_PROCESS_RESULT_INTERVAL': 200,\n",
            "           'LEARNING_PROCESS_RESULT_LOSS_PATH': 'result/Seq2seq_loss.txt',\n",
            "           'LEARNING_PROCESS_RESULT_SAVE': True,\n",
            "           'LOSS_FUNCTION': NLLLoss(),\n",
            "           'MINIBATCH': 32,\n",
            "           'MODEL_D_SAVE_PATH': 'models/Seq2seq_D_{}.pt',\n",
            "           'MODEL_SAVE_INTERVAL': 200,\n",
            "           'OPTIMIZER_D': <class 'torch.optim.adam.Adam'>,\n",
            "           'OPTIMIZER_E': <class 'torch.optim.adam.Adam'>}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfhZkkxckhEZ",
        "colab_type": "text"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHSZpaajkhEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(torch.nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = args\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x.reshape(self.shape)\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        dim = cfg.SEQ2SEQ_HIDDEN_DIM\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            torch.nn.Embedding(input_dim, dim),\n",
        "            torch.nn.ReLU(),\n",
        "            Reshape(1, 1, -1)\n",
        "        )\n",
        "\n",
        "        self.gru = torch.nn.GRU(dim, dim)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        return x, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, cfg.SEQ2SEQ_HIDDEN_DIM, device=cfg.DEVICE)\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        dim = cfg.SEQ2SEQ_HIDDEN_DIM\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            torch.nn.Embedding(output_dim, dim),\n",
        "            torch.nn.ReLU(),\n",
        "            Reshape(1, 1, -1)\n",
        "        )\n",
        "        self.gru = torch.nn.GRU(dim, dim)\n",
        "\n",
        "        self.out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(dim, output_dim),\n",
        "            torch.nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        x = self.out(x[:, 0])\n",
        "        return x, hidden\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, cfg.SEQ2SEQ_HIDDEN_DIM, device=cfg.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWdUenQ8khEc",
        "colab_type": "text"
      },
      "source": [
        "## Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw9HD3tjkhEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MInibatch_Generator():\n",
        "    def __init__(self, data_size, batch_size, shuffle=True):\n",
        "        self.data_size = data_size\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.mbi = 0 # index for iteration\n",
        "        self.inds = np.arange(data_size)\n",
        "        np.random.shuffle(self.inds)\n",
        "\n",
        "    def __call__(self):\n",
        "        if self.mbi + self.batch_size > self.data_size:\n",
        "            inds = self.inds[self.mbi:]\n",
        "            np.random.shuffle(self.inds)\n",
        "            inds = np.hstack((inds, self.inds[ : (self.batch_size - (self.data_size - self.mbi))]))\n",
        "            mbi = self.batch_size - (self.data_size - self.mbi)\n",
        "        else:\n",
        "            inds = self.inds[self.mbi : self.mbi + self.batch_size]\n",
        "            self.mbi += self.batch_size\n",
        "        return inds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvsBhxJzkhEe",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "u93U8jihkhEe",
        "colab_type": "code",
        "outputId": "c0126574-74b0-45e0-a8e2-ea2d0f2519c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# train\n",
        "def train():\n",
        "    # model\n",
        "    E = Encoder(cfg.CORPUS1_NUM).to(cfg.DEVICE)\n",
        "    D = Decoder(cfg.CORPUS2_NUM).to(cfg.DEVICE)\n",
        "\n",
        "    #summary(E, (cfg.INPUT_Z_DIM, 1, 1), device=cfg.DEVICE_TYPE)\n",
        "    #summary(D, (cfg.OUTPUT_CHANNEL, cfg.OUTPUT_HEIGHT, cfg.OUTPUT_WIDTH), device=cfg.DEVICE_TYPE)\n",
        "    \n",
        "    opt_E = cfg.TRAIN.OPTIMIZER_E(E.parameters(), **cfg.TRAIN.LEARNING_PARAMS_E)\n",
        "    opt_D = cfg.TRAIN.OPTIMIZER_D(D.parameters(), **cfg.TRAIN.LEARNING_PARAMS_D)\n",
        "\n",
        "    list_iter = []\n",
        "    list_loss = []\n",
        "    list_accuracy = []\n",
        "\n",
        "    #dataset = MyDataset(data_dict['data1'], data_dict['data2'])\n",
        "    #dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.TRAIN.MINIBATCH, shuffle=True)\n",
        "\n",
        "    mb_gen = MInibatch_Generator(len(data_dict['data1']), cfg.TRAIN.MINIBATCH)\n",
        "\n",
        "    print('training start')\n",
        "    progres_bar = ''\n",
        "\n",
        "    Xs_train = data_dict['data1']\n",
        "    ts_train = data_dict['data2']\n",
        "\n",
        "    for i in range(cfg.TRAIN.ITERATION):\n",
        "        idxs = mb_gen()\n",
        "        loss = 0.\n",
        "        accuracy = 0.\n",
        "        total_len = 0.\n",
        "        _Xs = [Xs_train[idx] for idx in idxs]\n",
        "        _ts = [ts_train[idx] for idx in idxs]\n",
        "\n",
        "        # each iteration in minibatch\n",
        "        opt_E.zero_grad()\n",
        "        opt_D.zero_grad()\n",
        "\n",
        "        for mbi in range(cfg.TRAIN.MINIBATCH):\n",
        "            Xs = torch.tensor(_Xs[mbi]).reshape(-1, 1).to(cfg.DEVICE)\n",
        "            ts = torch.tensor(_ts[mbi]).reshape(-1, 1).to(cfg.DEVICE)\n",
        "        \n",
        "            xs_length = Xs.size()[0]\n",
        "            ts_length = ts.size()[0]\n",
        "            total_len += ts_length\n",
        "\n",
        "            # encode process\n",
        "            E_hidden = E.initHidden() # initialize encoder hidden\n",
        "            for ei in range(xs_length):\n",
        "                E_output, E_hidden = E(Xs[ei], E_hidden)\n",
        "\n",
        "            # decode process\n",
        "            D_xs = ts[0] # define decoder input\n",
        "            D_hidden = E_hidden # define decoder hidden\n",
        "            D_outputs = []\n",
        "\n",
        "            # define whethere if use teacher label for decoder input\n",
        "            use_teacher = True if np.random.random() < cfg.SEQ2SEQ_TRAIN_FORCE_PROB else False\n",
        "\n",
        "            for di in range(1, ts_length):\n",
        "                # decode\n",
        "                D_ys, D_hidden = D(D_xs, D_hidden)\n",
        "\n",
        "                # add loss\n",
        "                loss += cfg.TRAIN.LOSS_FUNCTION(torch.log(D_ys), ts[di])\n",
        "\n",
        "                # count accuracy\n",
        "                if D_ys.argmax() == ts[di]:\n",
        "                    accuracy += 1.\n",
        "                \n",
        "                if cfg.SEQ2SEQ_NEXT_WORD_SELECTION == \"argmax\":\n",
        "                    topv, topi = D_ys.data.topk(1)\n",
        "\n",
        "                elif cfg.SEQ2SEQ_NEXT_WORD_SELECTION == \"prob\":\n",
        "                    topi = torch.multinomial(torch.max(D_ys, torch.zeros_like(D_ys)), 1)\n",
        "                \n",
        "                # define next decoder input\n",
        "                if use_teacher:\n",
        "                    D_xs = ts[di] # teacher forcing\n",
        "                else:\n",
        "                    D_xs = topi#.squeeze().detach()\n",
        "\n",
        "                D_outputs.append(topi.item())\n",
        "                     \n",
        "                # if EOS, finish training\n",
        "                #if D_xs.item() == data_dict['corpus2'].index('<EOS>'):\n",
        "                #    break\n",
        "\n",
        "        loss.backward()\n",
        "        opt_D.step()\n",
        "\n",
        "        _loss = loss.item() / cfg.TRAIN.MINIBATCH\n",
        "        _accuracy = accuracy / total_len\n",
        "\n",
        "        progres_bar += '|'\n",
        "        print('\\r' + 'Loss:{:.4f}, Accu:{:.4f} '.format(_loss, _accuracy) + progres_bar, end='')\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            progres_bar += str(i + 1)\n",
        "            print('\\r' + 'Loss:{:.4f}, Accu:{:.4f} '.format(_loss, _accuracy) + progres_bar, end='')\n",
        "\n",
        "            # save process result\n",
        "            if cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE:\n",
        "                list_iter.append(i + 1)\n",
        "                list_loss.append(_loss)\n",
        "                list_accuracy.append(_accuracy)\n",
        "\n",
        "        # display training state\n",
        "        if (i + 1) % cfg.TRAIN.DISPAY_ITERATION_INTERVAL == 0:\n",
        "            print('\\r' + ' ' * (len(progres_bar) + 50), end='')\n",
        "            print('\\rIter:{}, Loss:{:.4f}, Accu:{:.4f}'.format(i + 1, _loss, _accuracy))\n",
        "            progres_bar = ''\n",
        "\n",
        "        # save parameters\n",
        "        if (cfg.TRAIN.MODEL_SAVE_INTERVAL != False) and ((i + 1) % cfg.TRAIN.MODEL_SAVE_INTERVAL == 0):\n",
        "            D_save_path = cfg.TRAIN.MODEL_D_SAVE_PATH.format('iter{}'.format(i + 1))\n",
        "            torch.save(D.state_dict(), D_save_path)\n",
        "            print('save D >> {}'.format(D_save_path))\n",
        "\n",
        "        # save process result\n",
        "        if cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE and ((i + 1) % cfg.TRAIN.LEARNING_PROCESS_RESULT_INTERVAL == 0):\n",
        "            print('iter :', i + 1)\n",
        "            print(' - [input]', ' '.join([data_dict['corpus1'][x] for x in _Xs[0][1:-1]]))\n",
        "            print(' - [output]', ' '.join([data_dict['corpus2'][x] for x in D_outputs if x not in [0, 1, 2]]))\n",
        "            print(' - [gt]', ' '.join([data_dict['corpus2'][x] for x in _ts[0][1:-1]]))\n",
        "\n",
        "    D_save_path = cfg.TRAIN.MODEL_D_SAVE_PATH.format('final')\n",
        "    torch.save(D.state_dict(), D_save_path)\n",
        "    print('final paramters were saved to D >> {}'.format(D_save_path))\n",
        "\n",
        "    if cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE:\n",
        "        f = open(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH, 'w')\n",
        "        df = pd.DataFrame({'iteration' : list_iter, 'loss' : list_loss, 'accuracy' : list_accuracy})\n",
        "        df.to_csv(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH, index=False)\n",
        "        print('loss was saved to >> {}'.format(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH))\n",
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training start\n",
            "Iter:50, Loss:5.5941, Accu:0.4370\n",
            "Iter:100, Loss:3.1492, Accu:0.5368\n",
            "Iter:150, Loss:3.4650, Accu:0.5500\n",
            "Iter:200, Loss:2.3020, Accu:0.5786\n",
            "save D >> models/Seq2seq_D_iter200.pt\n",
            "iter : 200\n",
            " - [input] We won\n",
            " - [output] Sois gentil \n",
            " - [gt] Nous avons gagné\n",
            "Iter:250, Loss:3.5187, Accu:0.4815\n",
            "Iter:300, Loss:3.0595, Accu:0.5396\n",
            "Iter:350, Loss:1.2297, Accu:0.6528\n",
            "Loss:2.7218, Accu:0.5362 ||||||||||360||||||||||370||"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADaElar6khEh",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjit-oNlkhEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "def test():\n",
        "    print('-' * 20)\n",
        "    print('test function')\n",
        "    print('-' * 20)\n",
        "    G = Generator().to(cfg.DEVICE)\n",
        "    G.load_state_dict(torch.load(cfg.TEST.MODEL_G_PATH, map_location=torch.device(cfg.DEVICE)))\n",
        "    G.eval()\n",
        "\n",
        "    np.random.seed(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in range(cfg.TEST.ITERATION):\n",
        "            z = np.random.uniform(-1, 1, size=(cfg.TEST.MINIBATCH, cfg.INPUT_Z_DIM))\n",
        "            z = torch.tensor(z, dtype=torch.float).to(cfg.DEVICE)\n",
        "\n",
        "            result_show(G, z, cfg.TEST.RESULT_IMAGE_PATH.format(i + 1), save=cfg.TEST.RESULT_SAVE, show=True, cmap=cfg.OUTPUT_CMAP)\n",
        "\n",
        "test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xGw8eZAkhEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def arg_parse():\n",
        "    parser = argparse.ArgumentParser(description='CNN implemented with Keras')\n",
        "    parser.add_argument('--train', dest='train', action='store_true')\n",
        "    parser.add_argument('--test', dest='test', action='store_true')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "# main\n",
        "if __name__ == '__main__':\n",
        "    args = arg_parse()\n",
        "\n",
        "    if args.train:\n",
        "        train()\n",
        "    if args.test:\n",
        "        test()\n",
        "\n",
        "    if not (args.train or args.test):\n",
        "        print(\"please select train or test flag\")\n",
        "        print(\"train: python main.py --train\")\n",
        "        print(\"test:  python main.py --test\")\n",
        "        print(\"both:  python main.py --train --test\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}